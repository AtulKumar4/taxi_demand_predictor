{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date=Timestamp('2023-07-12 11:00:00')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "current_date = pd.to_datetime(datetime.utcnow()).floor('H') # - timedelta(hours=1)\n",
    "print(f'{current_date=}')\n",
    "# current_date = pd.Timestamp('2023-02-28 09:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/72876\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Fetching data from 2023-06-14 11:00:00 to 2023-07-12 10:00:00\n",
      "2023-07-12 16:43:13,040 INFO: USE `taxi_demand_first_featurestore`\n",
      "2023-07-12 16:43:13,766 INFO: SELECT `fg0`.`pickup_hour` `pickup_hour`, `fg0`.`rides` `rides`, `fg0`.`pickup_location_id` `pickup_location_id`\n",
      "FROM `taxi_demand_first_featurestore`.`time_series_hourly_feature_group_1` `fg0`\n",
      "WHERE `fg0`.`pickup_hour` >= TIMESTAMP '2023-06-13 11:00:00.000' AND `fg0`.`pickup_hour` < TIMESTAMP '2023-07-13 10:00:00.000'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Time-series data is not complete. Make sure your feature pipeline is up and runnning.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m load_batch_of_features_from_store\n\u001b[1;32m----> 3\u001b[0m features \u001b[39m=\u001b[39m load_batch_of_features_from_store(current_date)\n",
      "File \u001b[1;32m~\\taxi_demand_predictor\\src\\inference.py:71\u001b[0m, in \u001b[0;36mload_batch_of_features_from_store\u001b[1;34m(current_date)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39m# validate we are not missing data in the feature store\u001b[39;00m\n\u001b[0;32m     70\u001b[0m location_ids \u001b[39m=\u001b[39m ts_data[\u001b[39m'\u001b[39m\u001b[39mpickup_location_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m---> 71\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(ts_data) \u001b[39m==\u001b[39m n_features\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(location_ids), \\\n\u001b[0;32m     72\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTime-series data is not complete. Make sure your feature pipeline is up and runnning.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[39m# sort data by location and time\u001b[39;00m\n\u001b[0;32m     75\u001b[0m ts_data\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpickup_location_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpickup_hour\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Time-series data is not complete. Make sure your feature pipeline is up and runnning."
     ]
    }
   ],
   "source": [
    "from src.inference import load_batch_of_features_from_store\n",
    "\n",
    "features = load_batch_of_features_from_store(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/72876\n"
     ]
    },
    {
     "ename": "NoHopsworksConnectionError",
     "evalue": "Connection is not active. Needs to be connected for model registry operations.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoHopsworksConnectionError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     load_model_from_registry,\n\u001b[0;32m      3\u001b[0m     get_model_predictions\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m load_model_from_registry()\n\u001b[0;32m      7\u001b[0m predictions \u001b[39m=\u001b[39m get_model_predictions(model, features)\n",
      "File \u001b[1;32m~\\taxi_demand_predictor\\src\\inference.py:103\u001b[0m, in \u001b[0;36mload_model_from_registry\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m    102\u001b[0m project \u001b[39m=\u001b[39m get_hopsworks_project()\n\u001b[1;32m--> 103\u001b[0m model_registry \u001b[39m=\u001b[39m project\u001b[39m.\u001b[39;49mget_model_registry()\n\u001b[0;32m    105\u001b[0m model \u001b[39m=\u001b[39m model_registry\u001b[39m.\u001b[39mget_model(\n\u001b[0;32m    106\u001b[0m     name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mMODEL_NAME,\n\u001b[0;32m    107\u001b[0m     version\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mMODEL_VERSION,\n\u001b[0;32m    108\u001b[0m )  \n\u001b[0;32m    110\u001b[0m model_dir \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdownload()\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hopsworks\\project.py:132\u001b[0m, in \u001b[0;36mProject.get_model_registry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m _client \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mget_instance()\n\u001b[0;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(_client) \u001b[39m==\u001b[39m Client:  \u001b[39m# If external client\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m connection(\n\u001b[0;32m    133\u001b[0m         host\u001b[39m=\u001b[39;49m_client\u001b[39m.\u001b[39;49m_host,\n\u001b[0;32m    134\u001b[0m         port\u001b[39m=\u001b[39;49m_client\u001b[39m.\u001b[39;49m_port,\n\u001b[0;32m    135\u001b[0m         project\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    136\u001b[0m         api_key_value\u001b[39m=\u001b[39;49m_client\u001b[39m.\u001b[39;49m_auth\u001b[39m.\u001b[39;49m_token,\n\u001b[0;32m    137\u001b[0m     )\u001b[39m.\u001b[39mget_model_registry()\n\u001b[0;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m connection()\u001b[39m.\u001b[39mget_model_registry()\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hsml\\connection.py:216\u001b[0m, in \u001b[0;36mConnection.connection\u001b[1;34m(cls, host, port, project, hostname_verification, trust_store_path, api_key_file, api_key_value)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnection\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     api_key_value: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    214\u001b[0m ):\n\u001b[0;32m    215\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Connection factory method, accessible through `hsml.connection()`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    217\u001b[0m         host,\n\u001b[0;32m    218\u001b[0m         port,\n\u001b[0;32m    219\u001b[0m         project,\n\u001b[0;32m    220\u001b[0m         hostname_verification,\n\u001b[0;32m    221\u001b[0m         trust_store_path,\n\u001b[0;32m    222\u001b[0m         api_key_file,\n\u001b[0;32m    223\u001b[0m         api_key_value,\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hsml\\connection.py:115\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, host, port, project, hostname_verification, trust_store_path, api_key_file, api_key_value)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_registry_api \u001b[39m=\u001b[39m model_registry_api\u001b[39m.\u001b[39mModelRegistryApi()\n\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_serving_api \u001b[39m=\u001b[39m model_serving_api\u001b[39m.\u001b[39mModelServingApi()\n\u001b[1;32m--> 115\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hsml\\decorators.py:25\u001b[0m, in \u001b[0;36mnot_connected.<locals>.if_not_connected\u001b[1;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mif\u001b[39;00m inst\u001b[39m.\u001b[39m_connected:\n\u001b[0;32m     24\u001b[0m     \u001b[39mraise\u001b[39;00m HopsworksConnectionError\n\u001b[1;32m---> 25\u001b[0m \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hsml\\connection.py:185\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m         client\u001b[39m.\u001b[39minit(\u001b[39m\"\u001b[39m\u001b[39minternal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_api \u001b[39m=\u001b[39m model_api\u001b[39m.\u001b[39mModelApi()\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_serving_api\u001b[39m.\u001b[39;49mload_default_configuration()  \u001b[39m# istio client, default resources,...\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mConnectionError\u001b[39;00m):\n\u001b[0;32m    187\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connected \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hsml\\core\\model_serving_api.py:56\u001b[0m, in \u001b[0;36mModelServingApi.load_default_configuration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load default configuration and set istio client for model serving\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m# kserve installed\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m is_kserve_installed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serving_api\u001b[39m.\u001b[39;49mis_kserve_installed()\n\u001b[0;32m     57\u001b[0m client\u001b[39m.\u001b[39mset_kserve_installed(is_kserve_installed)\n\u001b[0;32m     59\u001b[0m \u001b[39m# istio client\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hsml\\core\\serving_api.py:242\u001b[0m, in \u001b[0;36mServingApi.is_kserve_installed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m _client \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mget_instance()\n\u001b[0;32m    241\u001b[0m path_params \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvariables\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkube_kserve_installed\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 242\u001b[0m kserve_installed \u001b[39m=\u001b[39m _client\u001b[39m.\u001b[39;49m_send_request(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, path_params)\n\u001b[0;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msuccessMessage\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kserve_installed\n\u001b[0;32m    245\u001b[0m     \u001b[39mand\u001b[39;00m kserve_installed[\u001b[39m\"\u001b[39m\u001b[39msuccessMessage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Atul\\taxi_demand_predictor\\.venv\\lib\\site-packages\\hsml\\decorators.py:34\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[1;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mif_connected\u001b[39m(inst, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inst\u001b[39m.\u001b[39m_connected:\n\u001b[1;32m---> 34\u001b[0m         \u001b[39mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mNoHopsworksConnectionError\u001b[0m: Connection is not active. Needs to be connected for model registry operations."
     ]
    }
   ],
   "source": [
    "from src.inference import (\n",
    "    load_model_from_registry,\n",
    "    get_model_predictions\n",
    ")\n",
    "\n",
    "model = load_model_from_registry()\n",
    "predictions = get_model_predictions(model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_demand</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-02-28 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pickup_location_id  predicted_demand         pickup_hour\n",
       "0                   264              48.0 2023-02-28 09:00:00\n",
       "1                    91               0.0 2023-02-28 09:00:00\n",
       "2                    97               2.0 2023-02-28 09:00:00\n",
       "3                   231              84.0 2023-02-28 09:00:00\n",
       "4                   165               1.0 2023-02-28 09:00:00\n",
       "..                  ...               ...                 ...\n",
       "260                 196               0.0 2023-02-28 09:00:00\n",
       "261                 203               0.0 2023-02-28 09:00:00\n",
       "262                  63               0.0 2023-02-28 09:00:00\n",
       "263                 190               0.0 2023-02-28 09:00:00\n",
       "264                   9               0.0 2023-02-28 09:00:00\n",
       "\n",
       "[265 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['pickup_hour'] = current_date\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save these predictions in the feature store, so they can be later consumed by our Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/12447\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "from src.feature_store_api import get_feature_store\n",
    "import src.config as config\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTIONS,\n",
    "    version=1,\n",
    "    description=\"Predictions generate by our production model\",\n",
    "    primary_key = ['pickup_location_id', 'pickup_hour'],\n",
    "    event_time='pickup_hour',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a52e71b9a5d4d54a43a9b9681cbacc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/265 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/12447/jobs/named/model_predictions_feature_group_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x131826b50>, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(predictions, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b98d97558a062384a76b0309256306c9ce5dd4e2074fe66c33532239207fc923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
